# test_set_completion.py
import sys
import os
from datetime import datetime, timedelta
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

# –î–û–ë–ê–í–ò–¢–¨ –≠–¢–£ –°–¢–†–û–ö–£:
from config import PRODUCTION_MODE

def create_test_set(level: str, set_name: str, word_count: int):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä —Å–ª–æ–≤ (–ü–û–õ–ù–û–°–¢–¨–Æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏)."""
    from pathlib import Path
    from config import LEVELS_DIR
    from utils.helpers import _words_file_cache, clear_words_file_cache
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º
    clear_words_file_cache()
    
    level_dir = Path(LEVELS_DIR) / level
    level_dir.mkdir(parents=True, exist_ok=True)
    
    if not PRODUCTION_MODE:
        print(f"üîç DEBUG create_test_set: –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {level_dir}")
        print(f"üîç DEBUG create_test_set: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {level_dir.exists()}")
    
    set_file = level_dir / f"{set_name}.txt"
    
    if not PRODUCTION_MODE:
        print(f"üîç DEBUG create_test_set: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É: {set_file}")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª
    if set_file.exists():
        set_file.unlink()
        if not PRODUCTION_MODE:
            print(f"üîç DEBUG create_test_set: –£–¥–∞–ª–µ–Ω —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ñ–∞–π–ª {set_file}")
    
    # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    words = []
    for i in range(1, word_count + 1):
        words.append(f"testword{i} - —Ç–µ—Å—Ç—Å–ª–æ–≤–æ{i}")
    
    if not PRODUCTION_MODE:
        print(f"üîç DEBUG create_test_set: –°–æ–∑–¥–∞–Ω–æ {len(words)} —Å–ª–æ–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏")
        print(f"üîç DEBUG create_test_set: –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ: '{words[0]}'")
        print(f"üîç DEBUG create_test_set: –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ: '{words[-1]}'")
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å —Å flush
    try:
        with open(set_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(words))
            f.flush()
            os.fsync(f.fileno())  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–ø–∏—Å—å –Ω–∞ –¥–∏—Å–∫
        
        if not PRODUCTION_MODE:
            print(f"üîç DEBUG create_test_set: –§–∞–π–ª –∑–∞–ø–∏—Å–∞–Ω —É—Å–ø–µ—à–Ω–æ")
            
    except Exception as e:
        print(f"üîç DEBUG create_test_set: –û–®–ò–ë–ö–ê –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞: {e}")
        raise
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Å–æ–∑–¥–∞–ª—Å—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ
    if set_file.exists():
        actual_words = []
        try:
            with open(set_file, 'r', encoding='utf-8') as f:
                actual_words = [line.strip() for line in f if line.strip()]
            
            if not PRODUCTION_MODE:
                print(f"üîç DEBUG create_test_set: –ü–†–û–í–ï–†–ö–ê - –°–æ–∑–¥–∞–Ω –Ω–∞–±–æ—Ä {set_name} —Å {len(actual_words)} —Å–ª–æ–≤–∞–º–∏")
                print(f"üîç DEBUG create_test_set: –ü–†–û–í–ï–†–ö–ê - –ü–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ: {actual_words[0] if actual_words else '–ü–£–°–¢–û'}")
                print(f"üîç DEBUG create_test_set: –ü–†–û–í–ï–†–ö–ê - –ü–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ: {actual_words[-1] if actual_words else '–ü–£–°–¢–û'}")
                print(f"üîç DEBUG create_test_set: –ü–†–û–í–ï–†–ö–ê - –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {set_file.stat().st_size} –±–∞–π—Ç")
                
            if len(actual_words) != word_count:
                raise ValueError(f"–§–∞–π–ª —Å–æ–∑–¥–∞–Ω –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ: –æ–∂–∏–¥–∞–ª–æ—Å—å {word_count}, –ø–æ–ª—É—á–µ–Ω–æ {len(actual_words)}")
                
        except Exception as e:
            print(f"üîç DEBUG create_test_set: –û–®–ò–ë–ö–ê –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —Ñ–∞–π–ª–∞: {e}")
            raise
    else:
        raise ValueError(f"–§–∞–π–ª {set_file} –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω")
    
    return words

def simulate_learning_words(chat_id: int, words_to_learn: list):
    """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –∏–∑—É—á–µ–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö —Å–ª–æ–≤ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø —Å –æ—Ç–ª–∞–¥–∫–æ–π)."""
    from database import crud
    from utils.visual_helpers import extract_english
    
    today = datetime.now().strftime("%Y-%m-%d")
    
    if not PRODUCTION_MODE:
        print(f"üîç DEBUG simulate_learning_words: –ò–∑—É—á–∞–µ–º {len(words_to_learn)} —Å–ª–æ–≤")
    
    for word in words_to_learn:
        english_part = extract_english(word)
        translation = word.split(" - ")[1] if " - " in word else f"–ø–µ—Ä–µ–≤–æ–¥_{english_part}"
        
        if not PRODUCTION_MODE:
            print(f"üîç DEBUG: –î–æ–±–∞–≤–ª—è–µ–º –≤ learned_words: '{english_part}' -> '{translation}'")
        
        crud.add_learned_word(chat_id, english_part, translation, today)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤–∏–ª–∏—Å—å
    if not PRODUCTION_MODE:
        learned_after = crud.get_learned_words(chat_id)
        print(f"üîç DEBUG: –ü–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –ë–î: {len(learned_after)} –≤—ã—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤")

def cleanup_test_user(chat_id: int):
    """–û—á–∏—â–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –≤—Å–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ –∫—ç—à–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø - –ù–ï —É–¥–∞–ª—è–µ–º TestSet —Ñ–∞–π–ª)."""
    from database.db import db_manager
    from utils.helpers import daily_words_cache, previous_daily_words, reset_daily_words_cache, clear_words_file_cache
    
    try:
        # –û—á–∏—â–∞–µ–º –ë–î
        with db_manager.transaction() as tx:
            tx.execute("DELETE FROM users WHERE chat_id = ?", (chat_id,))
            tx.execute("DELETE FROM dictionary WHERE chat_id = ?", (chat_id,))
            tx.execute("DELETE FROM learned_words WHERE chat_id = ?", (chat_id,))
        
        # –û—á–∏—â–∞–µ–º –≤—Å–µ –∫—ç—à–∏
        reset_daily_words_cache(chat_id)
        if chat_id in previous_daily_words:
            del previous_daily_words[chat_id]
            
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ —Ñ–∞–π–ª–æ–≤
        clear_words_file_cache()
            
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ù–ï —É–¥–∞–ª—è–µ–º TestSet —Ñ–∞–π–ª—ã –∑–¥–µ—Å—å, –æ–Ω–∏ —É–¥–∞–ª—è—é—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ
            
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: {e}")

def setup_test_user(chat_id: int, level: str = "A1", words_per_day: int = 10):
    """–°–æ–∑–¥–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)."""
    from database import crud
    from handlers.settings import user_set_selection
    
    # –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    cleanup_test_user(chat_id)
    
    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    crud.add_user(chat_id)
    crud.update_user_level(chat_id, level)
    crud.update_user_words_per_day(chat_id, words_per_day)
    crud.update_user_notifications(chat_id, 3)  # 3 –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
    test_set = "TestSet"
    
    # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω–∞–±–æ—Ä –≤ –ë–î –∏ –≤ user_set_selection
    crud.update_user_chosen_set(chat_id, test_set)
    user_set_selection[chat_id] = test_set
    
    if not PRODUCTION_MODE:
        print(f"üîç DEBUG setup_test_user: –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞–±–æ—Ä {test_set} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {chat_id}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞–±–æ—Ä —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø—Ä–∞–≤–∏–ª—å–Ω–æ
        user = crud.get_user(chat_id)
        print(f"üîç DEBUG setup_test_user: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∏–∑ –ë–î: {user}")
        print(f"üîç DEBUG setup_test_user: user_set_selection: {user_set_selection.get(chat_id)}")
        
        # –î–û–ë–ê–í–õ–ï–ù–ò–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ–∞–π–ª —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –ù–ï —É–¥–∞–ª–µ–Ω
        from pathlib import Path
        from config import LEVELS_DIR
        test_file = Path(LEVELS_DIR) / level / f"{test_set}.txt"
        print(f"üîç DEBUG setup_test_user: –§–∞–π–ª TestSet —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ü–û–°–õ–ï setup: {test_file.exists()}")
        if test_file.exists():
            print(f"üîç DEBUG setup_test_user: –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ TestSet: {test_file.stat().st_size}")
    
    return test_set

def simulate_leftover_transition(chat_id: int, leftover_words: list):
    """–°–∏–º—É–ª–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –¥–Ω—é —Å leftover —Å–ª–æ–≤–∞–º–∏."""
    from utils.helpers import previous_daily_words, reset_daily_words_cache
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º leftover —Å–ª–æ–≤–∞ –≤ previous_daily_words
    if leftover_words:
        previous_daily_words[chat_id] = leftover_words
    elif chat_id in previous_daily_words:
        del previous_daily_words[chat_id]
    
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∫—ç—à, –Ω–æ –Ω–µ previous_daily_words
    reset_daily_words_cache(chat_id)

def get_daily_words_info(chat_id: int, force_new_day: bool = False):
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ª–æ–≤–∞—Ö –¥–Ω—è (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)."""
    from utils.helpers import get_daily_words_for_user
    from config import REMINDER_START, DURATION_HOURS
    from database import crud
    
    user = crud.get_user(chat_id)
    if not user:
        return None
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º force_reset —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ force_new_day = True
    result = get_daily_words_for_user(
        chat_id, user[1], user[2], user[3],
        first_time=REMINDER_START, duration_hours=DURATION_HOURS,
        force_reset=force_new_day
    )
    
    if result is None:
        return None
        
    messages, times = result
    
    # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫—ç—à–∞
    from utils.helpers import daily_words_cache
    cache_entry = daily_words_cache.get(chat_id)
    
    if cache_entry and len(cache_entry) >= 11:
        is_revision = cache_entry[9]
        unique_words = cache_entry[8]
        prefix = cache_entry[10]
    else:
        is_revision = False
        unique_words = []
        prefix = ""
    
    return {
        "messages": messages,
        "times": times,
        "unique_words": unique_words,
        "is_revision": is_revision,
        "prefix": prefix,
        "word_messages": messages,
        "total_notifications": len(messages)
    }

def test_normal_learning_phase():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–±—ã—á–Ω—É—é —Ñ–∞–∑—É –∏–∑—É—á–µ–Ω–∏—è."""
    print("\nüß™ –¢–ï–°–¢ 1: –û–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞ –∏–∑—É—á–µ–Ω–∏—è")
    print("=" * 50)
    
    chat_id = 999001
    total_words = 45
    words_per_day = 10
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        print(f"üìö –°–æ–∑–¥–∞–Ω –Ω–∞–±–æ—Ä: {total_words} —Å–ª–æ–≤, –Ω–∞—Å—Ç—Ä–æ–π–∫–∞: {words_per_day} —Å–ª–æ–≤/–¥–µ–Ω—å")
        
        # –î–µ–Ω—å 1: –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 10 –Ω–æ–≤—ã—Ö —Å–ª–æ–≤
        info = get_daily_words_info(chat_id, force_new_day=True)
        assert info is not None, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –¥–Ω—è"
        assert len(info["unique_words"]) == words_per_day, f"–û–∂–∏–¥–∞–ª–æ—Å—å {words_per_day} —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])}"
        assert not info["is_revision"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
        assert not info["prefix"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è"
        
        print(f"‚úÖ –î–µ–Ω—å 1: {len(info['unique_words'])} —Å–ª–æ–≤, —Ä–µ–∂–∏–º: –æ–±—ã—á–Ω—ã–π")
        
        # –ò–∑—É—á–∞–µ–º 8 –∏–∑ 10 —Å–ª–æ–≤ (2 –æ—Å—Ç–∞—é—Ç—Å—è –Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã–º–∏)
        words_to_learn = info["unique_words"][:8]
        leftover_words = info["unique_words"][8:]
        simulate_learning_words(chat_id, words_to_learn)
        
        print(f"üìñ –í—ã—É—á–µ–Ω–æ: {len(words_to_learn)} —Å–ª–æ–≤, –æ—Å—Ç–∞–ª–æ—Å—å –Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã–º–∏: {len(leftover_words)}")
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –¥–Ω—é —Å leftover —Å–ª–æ–≤–∞–º–∏
        simulate_leftover_transition(chat_id, leftover_words)
        
        # –î–µ–Ω—å 2: –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 2 + 8 = 10 —Å–ª–æ–≤
        info = get_daily_words_info(chat_id, force_new_day=True)
        assert len(info["unique_words"]) == words_per_day, f"–û–∂–∏–¥–∞–ª–æ—Å—å {words_per_day} —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])}"
        assert not info["is_revision"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ leftover —Å–ª–æ–≤–∞ –≤–∫–ª—é—á–µ–Ω—ã
        leftover_found = sum(1 for word in leftover_words if word in info["unique_words"])
        assert leftover_found == len(leftover_words), f"–ù–µ –≤—Å–µ leftover —Å–ª–æ–≤–∞ –Ω–∞–π–¥–µ–Ω—ã: {leftover_found}/{len(leftover_words)}"
        
        print(f"‚úÖ –î–µ–Ω—å 2: {len(info['unique_words'])} —Å–ª–æ–≤ (–≤–∫–ª—é—á–∞—è {leftover_found} leftover)")
        
        # –ò–∑—É—á–∞–µ–º –≤—Å–µ 10 —Å–ª–æ–≤
        simulate_learning_words(chat_id, info["unique_words"])
        
        print("üìñ –í—ã—É—á–µ–Ω–æ: –≤—Å–µ 10 —Å–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å
        from database import crud
        learned = crud.get_learned_words(chat_id)
        print(f"üéØ –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {len(learned)}/{total_words} —Å–ª–æ–≤")
        
        assert len(learned) == 18, f"–û–∂–∏–¥–∞–ª–æ—Å—å 18 –≤—ã—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(learned)}"
        
        print("‚úÖ –¢–ï–°–¢ 1 –ü–†–û–ô–î–ï–ù: –û–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 1 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_remainder_phase():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–∞–∑—É –æ—Å—Ç–∞—Ç–∫–æ–≤."""
    print("\nüß™ –¢–ï–°–¢ 2: –§–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤")
    print("=" * 50)
    
    chat_id = 999002
    total_words = 45
    words_per_day = 10
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º —Å–∏—Ç—É–∞—Ü–∏—é: –≤—ã—É—á–µ–Ω–æ 38 —Å–ª–æ–≤, –æ—Å—Ç–∞–ª–æ—Å—å 7
        words_to_learn = words[:38]
        simulate_learning_words(chat_id, words_to_learn)
        
        print(f"üìö –í—ã—É—á–µ–Ω–æ: {len(words_to_learn)} —Å–ª–æ–≤, –æ—Å—Ç–∞–ª–æ—Å—å: {total_words - len(words_to_learn)}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞ –¥–Ω—è - –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 7 —Å–ª–æ–≤ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
        info = get_daily_words_info(chat_id, force_new_day=True)
        remaining_count = total_words - len(words_to_learn)
        
        assert info is not None, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –¥–Ω—è"
        
        # –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤")
        print(f"üîç –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {info['is_revision']}")
        print(f"üîç –ü—Ä–µ—Ñ–∏–∫—Å: {info['prefix'][:50] if info['prefix'] else '–ù–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–∞'}")
        
        assert len(info["unique_words"]) == remaining_count, f"–û–∂–∏–¥–∞–ª–æ—Å—å {remaining_count} —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])}"
        assert not info["is_revision"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
        assert info["prefix"].startswith("‚ö†Ô∏è"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö"
        assert str(remaining_count) in info["prefix"], "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"
        
        print(f"‚úÖ –§–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤: {len(info['unique_words'])} —Å–ª–æ–≤")
        print(f"‚úÖ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {info['prefix'][:50]}...")
        
        print("‚úÖ –¢–ï–°–¢ 2 –ü–†–û–ô–î–ï–ù: –§–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 2 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_revision_phase():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ä–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è."""
    print("\nüß™ –¢–ï–°–¢ 3: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è")
    print("=" * 50)
    
    chat_id = 999003
    total_words = 45
    words_per_day = 10
    
    try:
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        # –ò–∑—É—á–∞–µ–º –í–°–ï —Å–ª–æ–≤–∞
        simulate_learning_words(chat_id, words)
        
        print(f"üìö –í—ã—É—á–µ–Ω–æ: –í–°–ï {len(words)} —Å–ª–æ–≤")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞ –¥–Ω—è - –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        info = get_daily_words_info(chat_id, force_new_day=True)
        
        assert info is not None, "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ª–æ–≤–∞ –¥–Ω—è"
        
        # –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø  
        print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤")
        print(f"üîç –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {info['is_revision']}")
        print(f"üîç –ü—Ä–µ—Ñ–∏–∫—Å: {info['prefix'][:50] if info['prefix'] else '–ù–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–∞'}")
        
        assert info["is_revision"], "–î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
        assert len(info["unique_words"]) == words_per_day, f"–í —Ä–µ–∂–∏–º–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å {words_per_day} —Å–ª–æ–≤"
        assert info["prefix"].startswith("üéì"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ"
        assert "–≤—ã—É—á–∏–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞" in info["prefix"], "–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ"
        
        print(f"‚úÖ –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {len(info['unique_words'])} —Å–ª–æ–≤")
        print(f"‚úÖ –ü–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ: {info['prefix'][:50]}...")
        
        print("‚úÖ –¢–ï–°–¢ 3 –ü–†–û–ô–î–ï–ù: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 3 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_leftover_words():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫—É –Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤ (leftover)."""
    print("\nüß™ –¢–ï–°–¢ 4: –û–±—Ä–∞–±–æ—Ç–∫–∞ leftover —Å–ª–æ–≤")
    print("=" * 50)
    
    chat_id = 999004
    total_words = 20
    words_per_day = 5
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        print(f"üìö –°–æ–∑–¥–∞–Ω –Ω–∞–±–æ—Ä: {total_words} —Å–ª–æ–≤, –Ω–∞—Å—Ç—Ä–æ–π–∫–∞: {words_per_day} —Å–ª–æ–≤/–¥–µ–Ω—å")
        
        # –î–µ–Ω—å 1: –ø–æ–ª—É—á–∞–µ–º 5 —Å–ª–æ–≤
        info = get_daily_words_info(chat_id, force_new_day=True)
        day1_words = info["unique_words"].copy()
        
        # –ò–∑—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ 3 –∏–∑ 5 —Å–ª–æ–≤ (2 –æ—Å—Ç–∞—é—Ç—Å—è leftover)
        learned_words = day1_words[:3]
        leftover_words = day1_words[3:]
        simulate_learning_words(chat_id, learned_words)
        
        print(f"üìñ –î–µ–Ω—å 1: –≤—ã—É—á–µ–Ω–æ {len(learned_words)}, leftover: {len(leftover_words)}")
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–µ—Ä–µ—Ö–æ–¥ –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å —Å leftover —Å–ª–æ–≤–∞–º–∏
        simulate_leftover_transition(chat_id, leftover_words)
        
        # –î–µ–Ω—å 2: –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 2 leftover + 3 –Ω–æ–≤—ã—Ö = 5 —Å–ª–æ–≤
        info = get_daily_words_info(chat_id, force_new_day=True)
        day2_words = info["unique_words"]
        
        assert len(day2_words) == words_per_day, f"–û–∂–∏–¥–∞–ª–æ—Å—å {words_per_day} —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(day2_words)}"
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ leftover —Å–ª–æ–≤–∞ –≤–∫–ª—é—á–µ–Ω—ã
        leftover_found = 0
        for leftover in leftover_words:
            if leftover in day2_words:
                leftover_found += 1
        
        assert leftover_found == len(leftover_words), f"–ù–µ –≤—Å–µ leftover —Å–ª–æ–≤–∞ –Ω–∞–π–¥–µ–Ω—ã: {leftover_found}/{len(leftover_words)}"
        
        print(f"‚úÖ –î–µ–Ω—å 2: {len(day2_words)} —Å–ª–æ–≤, –≤–∫–ª—é—á–∞—è {leftover_found} leftover")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞
        new_words = [w for w in day2_words if w not in leftover_words]
        expected_new = words_per_day - len(leftover_words)
        assert len(new_words) == expected_new, f"–û–∂–∏–¥–∞–ª–æ—Å—å {expected_new} –Ω–æ–≤—ã—Ö —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(new_words)}"
        
        print(f"‚úÖ –ù–æ–≤—ã—Ö —Å–ª–æ–≤: {len(new_words)}")
        
        print("‚úÖ –¢–ï–°–¢ 4 –ü–†–û–ô–î–ï–ù: Leftover —Å–ª–æ–≤–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 4 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_quiz_behavior():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–≤–µ–¥–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö."""
    print("\nüß™ –¢–ï–°–¢ 5: –ü–æ–≤–µ–¥–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤")
    print("=" * 50)
    
    chat_id = 999005
    total_words = 10
    words_per_day = 5
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–±–æ–ª—å—à–æ–π –Ω–∞–±–æ—Ä
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º —Ç–µ—Å—Ç–∞
        info = get_daily_words_info(chat_id, force_new_day=True)
        
        from utils.helpers import daily_words_cache
        from utils.visual_helpers import extract_english
        from database import crud
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º –∑–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞
        learned = {extract_english(w[0]).lower() for w in crud.get_learned_words(chat_id)}
        
        entry = daily_words_cache.get(chat_id)
        unique_words = entry[8] if entry and len(entry) > 8 else []
        revision = bool(len(entry) > 9 and entry[9]) if entry else False
        
        if revision:
            source = unique_words
        else:
            source = [w for w in unique_words if extract_english(w).lower() not in learned]
        
        print(f"üìù –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: {len(source)} —Å–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞, revision={revision}")
        assert len(source) == words_per_day, "–í –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –¥–æ–ª–∂–Ω—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤—Å–µ —Å–ª–æ–≤–∞ –¥–Ω—è"
        assert not revision, "–í –æ–±—ã—á–Ω–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ñ–ª–∞–≥–∞ revision"
        
        # –ò–∑—É—á–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞
        simulate_learning_words(chat_id, words)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        info = get_daily_words_info(chat_id, force_new_day=True)
        entry = daily_words_cache.get(chat_id)
        unique_words = entry[8] if entry and len(entry) > 8 else []
        revision = bool(len(entry) > 9 and entry[9]) if entry else False
        
        learned = {extract_english(w[0]).lower() for w in crud.get_learned_words(chat_id)}
        
        if revision:
            source = unique_words
        else:
            source = [w for w in unique_words if extract_english(w).lower() not in learned]
        
        print(f"üìù –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {len(source)} —Å–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∞, revision={revision}")
        assert revision, "–í —Ä–µ–∂–∏–º–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ñ–ª–∞–≥ revision"
        assert len(source) == words_per_day, "–í —Ä–µ–∂–∏–º–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤"
        
        print("‚úÖ –¢–ï–°–¢ 5 –ü–†–û–ô–î–ï–ù: –¢–µ—Å—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 5 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_edge_cases():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏."""
    print("\nüß™ –¢–ï–°–¢ 6: –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏")
    print("=" * 50)
    
    try:
        # –°–ª—É—á–∞–π 1: –ù–∞–±–æ—Ä –º–µ–Ω—å—à–µ —á–µ–º words_per_day
        print("\nüî∏ –°–ª—É—á–∞–π 1: –ù–∞–±–æ—Ä –º–µ–Ω—å—à–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞")
        chat_id = 999006
        total_words = 3
        words_per_day = 10
        
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        info = get_daily_words_info(chat_id, force_new_day=True)
        
        # –û–¢–õ–ê–î–û–ß–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø
        print(f"üîç –û—Ç–ª–∞–¥–∫–∞: –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤")
        print(f"üîç –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: {info['is_revision']}")
        print(f"üîç –ü—Ä–µ—Ñ–∏–∫—Å: {info['prefix'][:50] if info['prefix'] else '–ù–µ—Ç –ø—Ä–µ—Ñ–∏–∫—Å–∞'}")
        
        assert len(info["unique_words"]) == total_words, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å {total_words} —Å–ª–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {len(info['unique_words'])}"
        assert info["prefix"].startswith("‚ö†Ô∏è"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"
        assert str(total_words) in info["prefix"], "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ"
        
        print(f"‚úÖ –°–ª—É—á–∞–π 1: {len(info['unique_words'])}/{total_words} —Å–ª–æ–≤ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º")
        cleanup_test_user(chat_id)
        
        # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Å–ª—É—á–∞–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
        
        print("‚úÖ –¢–ï–°–¢ 6 –ü–†–û–ô–î–ï–ù: –í—Å–µ –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 6 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_transition_phases():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ñ–∞–∑–∞–º–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê)."""
    print("\nüß™ –¢–ï–°–¢ 7: –ü–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ñ–∞–∑–∞–º–∏")
    print("=" * 50)
    
    chat_id = 999009
    total_words = 15
    words_per_day = 7
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–∞–±–æ—Ä
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        # –§–∞–∑–∞ 1: –û–±—ã—á–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ (–¥–µ–Ω—å 1)
        print("\nüìÖ –î–µ–Ω—å 1: –û–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞")
        info = get_daily_words_info(chat_id, force_new_day=True)
        assert len(info["unique_words"]) == words_per_day, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤"
        assert not info["is_revision"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
        assert not info["prefix"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å–∞"
        
        # –ò–∑—É—á–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –¥–Ω—è 1
        simulate_learning_words(chat_id, info["unique_words"])
        print(f"‚úÖ –î–µ–Ω—å 1: {len(info['unique_words'])} —Å–ª–æ–≤ –∏–∑—É—á–µ–Ω–æ")
        
        # –§–∞–∑–∞ 2: –ï—â–µ –æ–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞ (–¥–µ–Ω—å 2) - –æ—Å—Ç–∞–ª–æ—Å—å 8 —Å–ª–æ–≤, –Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ 7
        print("\nüìÖ –î–µ–Ω—å 2: –ï—â–µ –æ–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞ (8 —Å–ª–æ–≤ –æ—Å—Ç–∞–ª–æ—Å—å, –Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ 7)")
        info = get_daily_words_info(chat_id, force_new_day=True)
        remaining = total_words - words_per_day  # 15 - 7 = 8
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–æ–≤ –±–æ–ª—å—à–µ —á–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ - —ç—Ç–æ –æ–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞
        if remaining > words_per_day:
            assert len(info["unique_words"]) == words_per_day, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å {words_per_day} —Å–ª–æ–≤ (–Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)"
            assert not info["is_revision"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è" 
            assert not info["prefix"], "–ù–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ—Ñ–∏–∫—Å–∞ –≤ –æ–±—ã—á–Ω–æ–π —Ñ–∞–∑–µ"
            print(f"‚úÖ –î–µ–Ω—å 2: {len(info['unique_words'])} —Å–ª–æ–≤ (–æ–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞)")
            
            # –ò–∑—É—á–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –¥–Ω—è 2
            simulate_learning_words(chat_id, info["unique_words"])
            
            # –î–µ–Ω—å 3: –¢–µ–ø–µ—Ä—å —Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ (–æ—Å—Ç–∞–ª–æ—Å—å 1 —Å–ª–æ–≤–æ)
            print("\nüìÖ –î–µ–Ω—å 3: –§–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤")
            info = get_daily_words_info(chat_id, force_new_day=True)
            final_remaining = total_words - words_per_day * 2  # 15 - 7*2 = 1
            assert len(info["unique_words"]) == final_remaining, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å {final_remaining} –æ—Å—Ç–∞—Ç–æ–∫"
            assert not info["is_revision"], "–ï—â–µ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
            assert info["prefix"].startswith("‚ö†Ô∏è"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö"
            
            print(f"‚úÖ –î–µ–Ω—å 3: {len(info['unique_words'])} —Å–ª–æ–≤–æ (—Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤)")
            
            # –ò–∑—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ
            simulate_learning_words(chat_id, info["unique_words"])
            
            # –î–µ–Ω—å 4: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
            print("\nüìÖ –î–µ–Ω—å 4: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è")
            info = get_daily_words_info(chat_id, force_new_day=True)
            assert len(info["unique_words"]) == words_per_day, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤"
            assert info["is_revision"], "–î–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
            assert info["prefix"].startswith("üéì"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ"
            
            print(f"‚úÖ –î–µ–Ω—å 4: {len(info['unique_words'])} —Å–ª–æ–≤ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è")
        else:
            # –ï—Å–ª–∏ remaining <= words_per_day, —Ç–æ —Å—Ä–∞–∑—É —Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
            assert len(info["unique_words"]) == remaining, f"–î–æ–ª–∂–Ω–æ –±—ã—Ç—å {remaining} –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Å–ª–æ–≤"
            assert not info["is_revision"], "–ï—â–µ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–µ–∂–∏–º–∞ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
            assert info["prefix"].startswith("‚ö†Ô∏è"), "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö"
            print(f"‚úÖ –î–µ–Ω—å 2: {len(info['unique_words'])} —Å–ª–æ–≤ (—Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤)")
        
        print("‚úÖ –¢–ï–°–¢ 7 –ü–†–û–ô–î–ï–ù: –ü–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ñ–∞–∑–∞–º–∏ —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 7 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_message_formatting():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–∞—Ö (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê)."""
    print("\nüß™ –¢–ï–°–¢ 8: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π")
    print("=" * 50)
    
    chat_id = 999010
    total_words = 12
    words_per_day = 5
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–∞–±–æ—Ä –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        from utils.visual_helpers import format_daily_words_message, truncate_daily_words_message
        
        # –¢–µ—Å—Ç 1: –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º
        print("\nüî∏ –¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º")
        info = get_daily_words_info(chat_id, force_new_day=True)
        formatted = format_daily_words_message(info["messages"], info["times"], "TestSet", total_words)
        
        assert "üìö –°–ª–æ–≤–∞—Ä—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è" in formatted, "–î–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫"
        assert "TestSet" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–∞"
        assert f"({total_words} —Å–ª–æ–≤)" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –Ω–∞–±–æ—Ä–µ"
        assert "‚è∞" in formatted, "–î–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤—Ä–µ–º–µ–Ω–∞"
        
        print("‚úÖ –û–±—ã—á–Ω—ã–π —Ä–µ–∂–∏–º: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        # –ò–∑—É—á–∞–µ–º –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–≤ —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ —Ñ–∞–∑–µ –æ—Å—Ç–∞—Ç–∫–æ–≤
        # –ù—É–∂–Ω–æ –∏–∑—É—á–∏—Ç—å —Å—Ç–æ–ª—å–∫–æ, —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª–æ—Å—å –º–µ–Ω—å—à–µ words_per_day
        words_to_learn = info["unique_words"][:3]  # –∏–∑—É—á–∞–µ–º 3 –∏–∑ 5
        leftover_words = info["unique_words"][3:]  # –æ—Å—Ç–∞–µ—Ç—Å—è 2 leftover
        simulate_learning_words(chat_id, words_to_learn)
        simulate_leftover_transition(chat_id, leftover_words)
        
        # –¢–µ–ø–µ—Ä—å –∏–∑—É—á–∏–º –µ—â–µ —Å–ª–æ–≤ —á—Ç–æ–±—ã –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã—Ö —Å—Ç–∞–ª–æ < words_per_day
        # –£ –Ω–∞—Å 12 —Å–ª–æ–≤, –∏–∑—É—á–∏–ª–∏ 3, –æ—Å—Ç–∞–ª–æ—Å—å 9. –ù—É–∂–Ω–æ –∏–∑—É—á–∏—Ç—å –µ—â–µ —á—Ç–æ–±—ã –æ—Å—Ç–∞–ª–æ—Å—å < 5
        # –ò–∑—É—á–∏–º –µ—â–µ 5 —Å–ª–æ–≤, —Ç–æ–≥–¥–∞ –æ—Å—Ç–∞–Ω–µ—Ç—Å—è 4 < 5
        info2 = get_daily_words_info(chat_id, force_new_day=True)  # –ø–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞ —Å leftover
        additional_to_learn = [w for w in info2["unique_words"] if w not in leftover_words][:5]
        simulate_learning_words(chat_id, additional_to_learn)
        
        # –¢–µ—Å—Ç 2: –†–µ–∂–∏–º –æ—Å—Ç–∞—Ç–∫–æ–≤ - —Ç–µ–ø–µ—Ä—å –¥–æ–ª–∂–Ω–æ –æ—Å—Ç–∞—Ç—å—Å—è –º–∞–ª–æ —Å–ª–æ–≤
        print("\nüî∏ –¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –†–µ–∂–∏–º –æ—Å—Ç–∞—Ç–∫–æ–≤")
        info = get_daily_words_info(chat_id, force_new_day=True)
        formatted = format_daily_words_message(info["messages"], info["times"], "TestSet", total_words)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤
        if info["prefix"].startswith("‚ö†Ô∏è"):
            assert "‚ö†Ô∏è" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ"
            assert "–Ω–µ–≤—ã—É—á–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ"
            print("‚úÖ –†–µ–∂–∏–º –æ—Å—Ç–∞—Ç–∫–æ–≤: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        else:
            # –ï—Å–ª–∏ –Ω–µ —Ñ–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤, –∏–∑—É—á–∏–º –≤—Å–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–ª–æ–≤–∞
            simulate_learning_words(chat_id, words)
            
            # –¢–µ—Å—Ç 3: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
            print("\nüî∏ –¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è")
            info = get_daily_words_info(chat_id, force_new_day=True)
            formatted = format_daily_words_message(info["messages"], info["times"], "TestSet", total_words)
            
            assert "üéì" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å –ø–æ–∑–¥—Ä–∞–≤–ª–µ–Ω–∏–µ"
            assert "–≤—ã—É—á–∏–ª–∏ –≤—Å–µ —Å–ª–æ–≤–∞" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"
            assert "–ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è" in formatted, "–î–æ–ª–∂–Ω–æ –±—ã—Ç—å —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è"
            
            print("‚úÖ –†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è: —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        # –¢–µ—Å—Ç –æ–±—Ä–µ–∑–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        print("\nüî∏ –¢–µ—Å—Ç –æ–±—Ä–µ–∑–∫–∏ –¥–ª–∏–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
        # –°–æ–∑–¥–∞–µ–º –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        long_message = "üìö –°–ª–æ–≤–∞—Ä—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è\n" + "‚Ä¢ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ —Å–ª–æ–≤–æ " * 200
        
        truncated = truncate_daily_words_message(
            long_message, info["unique_words"], words_per_day, 3, "TestSet", total_words
        )
        
        assert len(truncated) < len(long_message), "–°–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –æ–±—Ä–µ–∑–∞–Ω–æ"
        assert len(truncated) <= 4000, "–û–±—Ä–µ–∑–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ª–∏–º–∏—Ç–∞"
        
        print("‚úÖ –û–±—Ä–µ–∑–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π: —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        print("‚úÖ –¢–ï–°–¢ 8 –ü–†–û–ô–î–ï–ù: –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 8 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def test_cache_consistency():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞."""
    print("\nüß™ –¢–ï–°–¢ 9: –ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞")
    print("=" * 50)
    
    chat_id = 999011
    total_words = 20
    words_per_day = 8
    
    try:
        # –°–æ–∑–¥–∞–µ–º –Ω–∞–±–æ—Ä –∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        words = create_test_set("A1", "TestSet", total_words)
        setup_test_user(chat_id, "A1", words_per_day)
        
        from utils.helpers import daily_words_cache, reset_daily_words_cache
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞ –¥–Ω—è - –¥–æ–ª–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å—Å—è –∫—ç—à
        info1 = get_daily_words_info(chat_id, force_new_day=True)
        assert chat_id in daily_words_cache, "–ö—ç—à –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω"
        
        # –ü–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ë–ï–ó force_new_day - –¥–æ–ª–∂–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫—ç—à
        info2 = get_daily_words_info(chat_id, force_new_day=False)
        assert info1["unique_words"] == info2["unique_words"], "–ö—ç—à –¥–æ–ª–∂–µ–Ω –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Ç–µ –∂–µ —Å–ª–æ–≤–∞"
        
        print("‚úÖ –ö—ç—à —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ")
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π —Å–±—Ä–æ—Å –∫—ç—à–∞
        reset_daily_words_cache(chat_id)
        assert chat_id not in daily_words_cache, "–ö—ç—à –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–±—Ä–æ—à–µ–Ω"
        
        # –ù–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ —Å–±—Ä–æ—Å–∞
        info3 = get_daily_words_info(chat_id, force_new_day=True)
        assert chat_id in daily_words_cache, "–ö—ç—à –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω"
        
        print("‚úÖ –°–±—Ä–æ—Å –∫—ç—à–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∫—ç—à–∞
        cache_entry = daily_words_cache[chat_id]
        assert len(cache_entry) >= 10, "–ö—ç—à –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –ø–æ–ª—è"
        assert cache_entry[0] == datetime.now().strftime("%Y-%m-%d"), "–î–∞—Ç–∞ –≤ –∫—ç—à–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–π"
        assert isinstance(cache_entry[8], list), "–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º"
        assert isinstance(cache_entry[9], bool), "–§–ª–∞–≥ revision –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±—É–ª–µ–≤—ã–º"
        
        print("‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∫—ç—à–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞")
        
        print("‚úÖ –¢–ï–°–¢ 9 –ü–†–û–ô–î–ï–ù: –ö—ç—à —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ")
        return True
        
    except Exception as e:
        print(f"‚ùå –¢–ï–°–¢ 9 –ü–†–û–í–ê–õ–ï–ù: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        cleanup_test_user(chat_id)

def run_all_tests():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ —Ç–µ—Å—Ç—ã."""
    print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –û–ö–û–ù–ß–ê–ù–ò–Ø –ù–ê–ë–û–†–ê")
    print("=" * 60)
    
    tests = [
        ("–û–±—ã—á–Ω–∞—è —Ñ–∞–∑–∞ –∏–∑—É—á–µ–Ω–∏—è", test_normal_learning_phase),
        ("–§–∞–∑–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤", test_remainder_phase),
        ("–†–µ–∂–∏–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è", test_revision_phase),
        ("–û–±—Ä–∞–±–æ—Ç–∫–∞ leftover —Å–ª–æ–≤", test_leftover_words),
        ("–ü–æ–≤–µ–¥–µ–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤", test_quiz_behavior),
        ("–ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏", test_edge_cases),
        ("–ü–µ—Ä–µ—Ö–æ–¥—ã –º–µ–∂–¥—É —Ñ–∞–∑–∞–º–∏", test_transition_phases),
        ("–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π", test_message_formatting),
        ("–ö–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫—ç—à–∞", test_cache_consistency),
    ]
    
    passed = 0
    failed = 0
    
    for test_name, test_func in tests:
        print(f"\n{'='*20} {test_name} {'='*20}")
        try:
            if test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê –≤ —Ç–µ—Å—Ç–µ '{test_name}': {e}")
            failed += 1
    
    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
    try:
        from pathlib import Path
        from config import LEVELS_DIR
        test_file = Path(LEVELS_DIR) / "A1" / "TestSet.txt"
        if test_file.exists():
            test_file.unlink()
    except Exception as e:
        print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –Ω–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: {e}")
    
    print("\n" + "="*60)
    print("üìä –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("="*60)
    print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {passed}")
    print(f"‚ùå –ü—Ä–æ–≤–∞–ª–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {failed}")
    print(f"üìà –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {passed/(passed+failed)*100:.1f}%")
    
    if failed == 0:
        print("\nüéâ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û!")
        print("‚úÖ –õ–æ–≥–∏–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –Ω–∞–±–æ—Ä–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –≤–æ –≤—Å–µ—Ö —Å—Ü–µ–Ω–∞—Ä–∏—è—Ö")
    else:
        print(f"\n‚ö†Ô∏è –ù–ê–ô–î–ï–ù–´ –ü–†–û–ë–õ–ï–ú–´ –í {failed} –¢–ï–°–¢–ê–•")
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥–∏–∫–∏")
    
    return failed == 0

if __name__ == "__main__":
    success = run_all_tests()
    if success:
        print("\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ. –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
    else:
        print("\nüîß –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—ã—è–≤–∏–ª–æ –ø—Ä–æ–±–ª–µ–º—ã. –¢—Ä–µ–±—É–µ—Ç—Å—è –æ—Ç–ª–∞–¥–∫–∞.")